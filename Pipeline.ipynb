{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipeline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxnzGlA8RuxW"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import pickle\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem.snowball import SnowballStemmer\r\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('vader_lexicon')\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAs6fHreR-VZ"
      },
      "source": [
        "def decontracted(text):\r\n",
        "    '''Funtion to expand the sentences which are in short forms'''\r\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\r\n",
        "    text = re.sub(r\"can\\'t\", \"can not\", text)\r\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\r\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\r\n",
        "    text = re.sub(r\"\\'s\", \" is\", text)\r\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\r\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\r\n",
        "    text = re.sub(r\"\\'t\", \" not\", text)\r\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\r\n",
        "    text = re.sub(r\"\\'m\", \" am\", text)\r\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR4WRSHWSARr"
      },
      "source": [
        "def remove_special_chars(text):\r\n",
        "  '''This function removes the special chars from the text'''\r\n",
        "  text = re.sub('[^A-Za-z0-9]+', ' ', text)\r\n",
        "  text=text.lower()\r\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeF5HCcsSCnB"
      },
      "source": [
        "stopWords=stopwords.words('english')\r\n",
        "stemmer=SnowballStemmer('english')\r\n",
        "\r\n",
        "#removing no,nor and not words from the english stopwords\r\n",
        "stopWords.remove('not')\r\n",
        "stopWords.remove('no')\r\n",
        "stopWords.remove('nor')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LNaDfbkSEOZ"
      },
      "source": [
        "def remove_stopwords(text):\r\n",
        "  '''This function removes the stopwords from the text'''\r\n",
        "  text=[word for word in text.split() if not word in stopWords]\r\n",
        "  text=' '.join(text)\r\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZzF4zB4SFnx"
      },
      "source": [
        "def stemming(text):\r\n",
        "  '''This function is to do stemming on words of text'''\r\n",
        "  text=' '.join([stemmer.stem(word) for word in text.split()])\r\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4suL6U5vSGyt"
      },
      "source": [
        "def preprocess_text(text):\r\n",
        "  '''This function does all the text preprocessing steps and return a clean text'''\r\n",
        "  text=decontracted(text)\r\n",
        "  text=remove_special_chars(text)\r\n",
        "  text=remove_stopwords(text)\r\n",
        "  text=stemming(text)\r\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85vLsnOiSIUJ"
      },
      "source": [
        "def get_embedding_features(data,word_embeddings,model_words):\r\n",
        "  '''This function takes dataframe as input and returns fasttext vecotr respresent of text data(Description)'''\r\n",
        "  vector_rep=[]\r\n",
        "  preprocessed_descriptions = data['Description'].values\r\n",
        "  for text in preprocessed_descriptions: # For each description\r\n",
        "    vector=np.zeros(300)\r\n",
        "    n=0\r\n",
        "    for word in text.split():# For each word in vector\r\n",
        "      if (word in model_words):\r\n",
        "        vec=word_embeddings[word] #Getting the word's w2v representation\r\n",
        "        vector+=vec\r\n",
        "        n+=1\r\n",
        "    if n!=0:\r\n",
        "      vector/=n\r\n",
        "    vector_rep.append(vector)\r\n",
        "  return np.array(vector_rep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0a6PgkPSJ-6"
      },
      "source": [
        "def get_word_char_lengths(data):\r\n",
        "  '''This function takes input dataframe and return with length of text by wordlevel and characterleve'''\r\n",
        "  length_features=[]\r\n",
        "  for index,row in data.iterrows():\r\n",
        "    text=row['Description']\r\n",
        "    length_wordlevel=len(text.split()) # Getting the number of words\r\n",
        "    len_charlevel=len(text) # Getting the number characters including spaces\r\n",
        "    length_features.append([length_wordlevel,len_charlevel])\r\n",
        "  return pd.DataFrame(length_features,columns=['length_word_level','length_char_level'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YVvS8p8SLW5"
      },
      "source": [
        "sid = SentimentIntensityAnalyzer()\r\n",
        "def sentiment_score(data):\r\n",
        "  '''This function takes dataframe as input and returns sentiment scores of text data'''\r\n",
        "  sentiments=[]\r\n",
        "  preprocessed_descriptions = data['Description'].values\r\n",
        "  for text in preprocessed_descriptions:\r\n",
        "    polarities=sid.polarity_scores(text) # Getting the sentiment scores of text\r\n",
        "    sentiments.append(list(polarities.values()))\r\n",
        "  return pd.DataFrame(sentiments,columns=['negative','neutral','positive','compound'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2cG2D2hSM0i"
      },
      "source": [
        "#Loading the models and files required\r\n",
        "\r\n",
        "model = pickle.load(open('lightgbm.pkl','rb'))\r\n",
        "\r\n",
        "scalar=pickle.load(open('scalar.pkl','rb'))\r\n",
        "\r\n",
        "glove_word_embeddings = pickle.load(open('glove_word_embeddings.pkl','rb'))\r\n",
        "glove_words=glove_word_embeddings.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH7NaOXBSOET"
      },
      "source": [
        "def get_vector_representation(query):\r\n",
        "  pre_query=preprocess_text(query)\r\n",
        "  qd=pd.DataFrame([pre_query],columns=['Description'])\r\n",
        "  quer_fasttext=get_embedding_features(qd,glove_word_embeddings,glove_words)\r\n",
        "  quer_fasttext=pd.DataFrame(quer_fasttext,columns=['embed_'+str(i) for i in range(300)])\r\n",
        "  query_lengths=get_word_char_lengths(qd)\r\n",
        "  qeury_sentiments=sentiment_score(qd)\r\n",
        "\r\n",
        "  vector=pd.concat([quer_fasttext,query_lengths,qeury_sentiments],axis=1)\r\n",
        "\r\n",
        "  vector=vector.values[0]\r\n",
        "  return vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNNKPocWWh8-",
        "outputId": "76622229-b50c-4028-a53d-c2c3c7142753"
      },
      "source": [
        "(get_vector_representation('leav')[:300]==np.zeros(300)).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR1Jbr95SPdK"
      },
      "source": [
        "def final_fun_1(queries):\r\n",
        "\r\n",
        "  queries_vec=[]\r\n",
        "  for query in queries:\r\n",
        "    vector=get_vector_representation(query)\r\n",
        "    queries_vec.append(vector)\r\n",
        "  queries_vec=np.asarray(queries_vec,)\r\n",
        "  queries_vec[:,300:]=scalar.transform(queries_vec[:,300:])\r\n",
        "\r\n",
        "  return model.predict(queries_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekvsjvYoSQ-J",
        "outputId": "6531eb27-8900-4e3f-bcb2-c80ac6e2acca"
      },
      "source": [
        "start = time.time()\r\n",
        "\r\n",
        "query=['''Catcalls and passing comments were two of the ghastly things the Delhi police at the International Airport put me and \r\n",
        "            my friend through. It is appalling that the protectors and law enforcers at the airport can make someone so uncomfortable.''',\r\n",
        "            '''Some people used to stare in a very inappropriate way which is not tolerable.It happened in the morning and Night.''']\r\n",
        "\r\n",
        "predictions=final_fun_1(query)\r\n",
        "\r\n",
        "labels=['Commenting','Ogling/Facial Expressions/Staring','Touching /Groping']\r\n",
        "\r\n",
        "for index,prediction in enumerate(predictions):\r\n",
        "  print('Query ',str(index),': ',end= '')\r\n",
        "  for i,val in enumerate(prediction):\r\n",
        "    if val==1:\r\n",
        "      print(labels[i],end=', ')\r\n",
        "  print('',end='\\n')\r\n",
        "\r\n",
        "\r\n",
        "end = time.time()\r\n",
        "\r\n",
        "print(f\"\\n \\nRuntime of the function is {end - start}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query  0 : Commenting, Ogling/Facial Expressions/Staring, \n",
            "Query  1 : Commenting, Touching /Groping, \n",
            "\n",
            " \n",
            "Runtime of the function is 0.014860391616821289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqdpxtYIYDy-"
      },
      "source": [
        "def final_fun_2(queries,target):\r\n",
        "\r\n",
        "  queries_vec=[]\r\n",
        "\r\n",
        "  for query in queries:\r\n",
        "    vector=get_vector_representation(query)\r\n",
        "    queries_vec.append(vector)\r\n",
        "  queries_vec=np.asarray(queries_vec,)\r\n",
        "  queries_vec[:,300:]=scalar.transform(queries_vec[:,300:])\r\n",
        "\r\n",
        "  y_pred=model.predict(queries_vec)\r\n",
        "  y_true=target\r\n",
        "  score=f1_score(y_true,y_pred,average='macro')\r\n",
        "  \r\n",
        "  return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g_3CTCfYedM",
        "outputId": "e9d40e06-5246-4ec9-c434-4c30f041cee3"
      },
      "source": [
        "start = time.time()\r\n",
        "\r\n",
        "query=['''Catcalls and passing comments were two of the ghastly things the Delhi police at the International Airport put me and \r\n",
        "            my friend through. It is appalling that the protectors and law enforcers at the airport can make someone so uncomfortable.''',\r\n",
        "            '''Some people used to stare in a very inappropriate way which is not tolerable.It happened in the morning and Night.''']\r\n",
        "\r\n",
        "targets=np.asarray([[1,1,0],[1,0,1]])\r\n",
        "\r\n",
        "score=final_fun_2(query,targets)\r\n",
        "\r\n",
        "print('F1-macro : ',score)\r\n",
        "\r\n",
        "end = time.time()\r\n",
        "\r\n",
        "print(f\"\\n \\nRuntime of the function is {end - start}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-macro :  1.0\n",
            "\n",
            " \n",
            "Runtime of the function is 0.020786046981811523\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}